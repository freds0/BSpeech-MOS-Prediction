{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3n9VACTf3u2z",
    "outputId": "32311008-acc4-40a7-fc74-9259c6f22d6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/resampy/interpn.py:114: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
      "  _resample_loop_p(x, t_out, interp_win, interp_delta, num_table, scale, y)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import torchaudio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CQqlhBbe4aAc",
    "outputId": "294d548d-97a6-46b2-dc95-5ca6fb4011c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 27 14:31:52 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   42C    P0    28W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "210fkQ-d4cQr",
    "outputId": "497ca5a3-99b0-46bf-f57a-0ae46c07e8ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dEZaRFJi4d8b",
    "outputId": "3ea73559-801e-49ab-e8ac-383127005f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
      "Collecting pip\n",
      "  Downloading pip-22.2-py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 7.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
      "Collecting gdown\n",
      "  Downloading gdown-4.5.1.tar.gz (14 kB)\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.7.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gdown: filename=gdown-4.5.1-py3-none-any.whl size=14951 sha256=6929e953daab53a8518a0af576701a3b352d39e96c83f115fb32207744ab3d67\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/ec/b0/a96d1d126183f98570a785e6bf8789fca559853a9260e928e1\n",
      "Successfully built gdown\n",
      "Installing collected packages: pip, gdown\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.1.3\n",
      "    Uninstalling pip-21.1.3:\n",
      "      Successfully uninstalled pip-21.1.3\n",
      "  Attempting uninstall: gdown\n",
      "    Found existing installation: gdown 4.4.0\n",
      "    Uninstalling gdown-4.4.0:\n",
      "      Successfully uninstalled gdown-4.4.0\n",
      "Successfully installed gdown-4.5.1 pip-22.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "wYlQuMKp4iYi",
    "outputId": "7b814aad-9513-44d0-8ddc-8cc10be362c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1eLVEr6dvycpzCBsW7qcpYE5LoSahgz_W\n",
      "To: /content/VCC2018_MOS_preprocessed.tar.bz\n",
      "100%|██████████| 1.32G/1.32G [00:10<00:00, 123MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'VCC2018_MOS_preprocessed.tar.bz'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://drive.google.com/file/d/1eLVEr6dvycpzCBsW7qcpYE5LoSahgz_W/view?usp=sharing\n",
    "import gdown, os\n",
    "os.chdir('/content')\n",
    "id = '1eLVEr6dvycpzCBsW7qcpYE5LoSahgz_W'\n",
    "url = \"https://drive.google.com/uc?id={}\".format(id)\n",
    "output = \"VCC2018_MOS_preprocessed.tar.bz\"\n",
    "\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzsXmqsZ4j3h"
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "tar = tarfile.open(output, \"r:bz2\")\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "znX75WeM4mA6",
    "outputId": "fa0ce5b9-859f-4dba-f284-a5b374d9c7bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-df4a751f-289e-47b2-8c63-98bef7d2881b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/content/VCC2018_MOS_preprocessed/wav/N14_VCC2...</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/content/VCC2018_MOS_preprocessed/wav/N14_VCC2...</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/content/VCC2018_MOS_preprocessed/wav/N14_VCC2...</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/content/VCC2018_MOS_preprocessed/wav/N14_VCC2...</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/content/VCC2018_MOS_preprocessed/wav/N14_VCC2...</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df4a751f-289e-47b2-8c63-98bef7d2881b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-df4a751f-289e-47b2-8c63-98bef7d2881b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-df4a751f-289e-47b2-8c63-98bef7d2881b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                            filepath  score\n",
       "0  /content/VCC2018_MOS_preprocessed/wav/N14_VCC2...   1.25\n",
       "1  /content/VCC2018_MOS_preprocessed/wav/N14_VCC2...   2.75\n",
       "2  /content/VCC2018_MOS_preprocessed/wav/N14_VCC2...   3.50\n",
       "3  /content/VCC2018_MOS_preprocessed/wav/N14_VCC2...   1.75\n",
       "4  /content/VCC2018_MOS_preprocessed/wav/N14_VCC2...   4.00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/content/VCC2018_MOS_preprocessed/mos_list.txt', header=None)\n",
    "df[0] = '/content/VCC2018_MOS_preprocessed/wav/' + df[0] \n",
    "df.columns = ['filepath', 'score']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oi16Cl5Y4oTC",
    "outputId": "bc191a16-b928-42d5-8160-68ed97eacd59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(df['score'].unique())\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3gaJdNiT4orB"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['score'])\n",
    "df['score'] = le.transform(df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DvtcqLje453s",
    "outputId": "79ddb2f3-b40f-41ae-fa78-38fb60b75703"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22360/22360 [00:13<00:00, 1604.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torchaudio\n",
    "data = []\n",
    "\n",
    "wavs_folder = '/content/VCC2018_MOS_preprocessed/wav/'\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    #filepath = os.path.join(wavs_folder, row['path'])\n",
    "    filepath = row['filepath']\n",
    "    score = row['score']\n",
    "    try:\n",
    "        # There are some broken files\n",
    "        s = torchaudio.load(filepath)\n",
    "        data.append({\n",
    "            # \"name\": name,\n",
    "            \"filepath\": filepath,\n",
    "            \"score\": score\n",
    "        })\n",
    "    except Exception as e:\n",
    "        #print(str(filepath), e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UA38SEcc47rP"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Y3eYY1ZG49YO",
    "outputId": "5cec2a8c-31a4-43d3-f8a2-2499cc8c9c08"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d9ed30c9-8fec-45d8-a065-45d7b3809e6f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/content/VCC2018_MOS_preprocessed/wav/N14_VCC2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/content/VCC2018_MOS_preprocessed/wav/N14_VCC2...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/content/VCC2018_MOS_preprocessed/wav/N14_VCC2...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/content/VCC2018_MOS_preprocessed/wav/N14_VCC2...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/content/VCC2018_MOS_preprocessed/wav/N14_VCC2...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20575</th>\n",
       "      <td>/content/VCC2018_MOS_preprocessed/wav/N14_VCC2...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20576</th>\n",
       "      <td>/content/VCC2018_MOS_preprocessed/wav/N10_VCC2...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20577</th>\n",
       "      <td>/content/VCC2018_MOS_preprocessed/wav/N09_VCC2...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20578</th>\n",
       "      <td>/content/VCC2018_MOS_preprocessed/wav/N11_VCC2...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20579</th>\n",
       "      <td>/content/VCC2018_MOS_preprocessed/wav/N06_VCC2...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20580 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9ed30c9-8fec-45d8-a065-45d7b3809e6f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d9ed30c9-8fec-45d8-a065-45d7b3809e6f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d9ed30c9-8fec-45d8-a065-45d7b3809e6f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                filepath  score\n",
       "0      /content/VCC2018_MOS_preprocessed/wav/N14_VCC2...      1\n",
       "1      /content/VCC2018_MOS_preprocessed/wav/N14_VCC2...      7\n",
       "2      /content/VCC2018_MOS_preprocessed/wav/N14_VCC2...     11\n",
       "3      /content/VCC2018_MOS_preprocessed/wav/N14_VCC2...      3\n",
       "4      /content/VCC2018_MOS_preprocessed/wav/N14_VCC2...     14\n",
       "...                                                  ...    ...\n",
       "20575  /content/VCC2018_MOS_preprocessed/wav/N14_VCC2...      6\n",
       "20576  /content/VCC2018_MOS_preprocessed/wav/N10_VCC2...     17\n",
       "20577  /content/VCC2018_MOS_preprocessed/wav/N09_VCC2...      3\n",
       "20578  /content/VCC2018_MOS_preprocessed/wav/N11_VCC2...      7\n",
       "20579  /content/VCC2018_MOS_preprocessed/wav/N06_VCC2...      2\n",
       "\n",
       "[20580 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eV5sOmu34--W"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMLXt7s95AVb"
   },
   "outputs": [],
   "source": [
    "categories_train = train_data['score'].to_list()\n",
    "audio_names_train = train_data['filepath'].to_list()\n",
    "\n",
    "categories_test = test_data['score'].to_list()\n",
    "audio_names_test = test_data['filepath'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnE04G135EWq",
    "outputId": "fc73a4bb-b806-442f-fab3-a2dedd58c1ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20]), (21,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all unique categories\n",
    "categories_types = np.sort(df['score'].unique())\n",
    "categories_types, categories_types.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6oas9tj5Gey"
   },
   "outputs": [],
   "source": [
    "# if we don't do preprocessing - saving specs - use this dataset \n",
    "class VCC2018MOSSpecDatasetLoad(Dataset):\n",
    "    def __init__(self, audio_names: list, labels: list):\n",
    "        self.audio_names = audio_names\n",
    "        self.labels = labels\n",
    "        self.transformation = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=16000,\n",
    "            n_fft=1024,\n",
    "            hop_length=512,\n",
    "            n_mels=80\n",
    "        )\n",
    "        #self.label_to_id = dict((mos,id) for id, mos in enumerate(labels))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.audio_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.audio_names[idx]\n",
    "        #waveform, sample_rate = torchaudio.load(filename)\n",
    "        wav, sr = torchaudio.load(filename)\n",
    "        mel_spec = self.transformation(wav).unsqueeze(1)\n",
    "\n",
    "        target = self.labels[idx]\n",
    "        \n",
    "        return {\"spec\": mel_spec, \"target\": target}\n",
    "\n",
    "    def get_transform_spec(self, idx, data_dir='./'):\n",
    "        # get audio path\n",
    "        specs = []\n",
    "        audio_name = self.audio_names[idx]\n",
    "        audio_path = os.path.join(data_dir, audio_name)\n",
    "          \n",
    "        # load audio and get its melspectrogram\n",
    "        audio_wave, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio_wave, sr=sr)\n",
    "        \n",
    "        mel_spec = librosa.power_to_db(mel_spec)\n",
    "        mel_spec = torch.Tensor(self.normalize(mel_spec)).unsqueeze(0)\n",
    "        return mel_spec        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lsLRG2hs5cBy"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence \n",
    "\n",
    "def wav_collate_fn(data):\n",
    "    \"\"\"\n",
    "       data: is a list of tuples with (example, label, length)\n",
    "             where 'example' is a tensor of arbitrary shape\n",
    "             and label/length are scalars\n",
    "    \"\"\"\n",
    "    features = [torch.tensor(d['spec']) for d in data] #(3)\n",
    "    labels = torch.tensor([d['target']  for d in data]) \n",
    "    new_features = pad_sequence([f.T for f in features], batch_first=True).squeeze()\n",
    "\n",
    "    return  {\n",
    "        'spec': new_features.to(device), \n",
    "        'target': labels.to(device)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvIhxM0l9F76"
   },
   "outputs": [],
   "source": [
    "dataset_train = VCC2018MOSSpecDatasetLoad(audio_names_train, categories_train)\n",
    "loader_train = DataLoader(dataset_train, batch_size=96, shuffle=True, collate_fn=wav_collate_fn)\n",
    "\n",
    "dataset_test = VCC2018MOSSpecDatasetLoad(audio_names_test, categories_test)\n",
    "loader_test = DataLoader(dataset_test, batch_size=8, shuffle=True, collate_fn=wav_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYbm3tCf9K6X",
    "outputId": "52095fdd-bcf4-46f5-864e-58e42a426d9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([96, 241, 80])\n",
      "0\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([96])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(loader_train):\n",
    "    print(type(batch['spec']))\n",
    "    print(batch['spec'].shape)\n",
    "    print(batch['spec'].get_device())\n",
    "    print(type(batch['target']))\n",
    "    print(batch['target'].shape)    \n",
    "    print(batch['target'].get_device())\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHx7nr4U5YeU"
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.avg_pool2d(x, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uIiZ9cZP5a3W"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            ConvBlock(in_channels=1, out_channels=64),\n",
    "            ConvBlock(in_channels=64, out_channels=128),\n",
    "            ConvBlock(in_channels=128, out_channels=256),\n",
    "            ConvBlock(in_channels=256, out_channels=512),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.mean(x, dim=3)\n",
    "        x, _ = torch.max(x, dim=2)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NcokWBs5ef4"
   },
   "outputs": [],
   "source": [
    "model = Classifier(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-F4XKbo779Z",
    "outputId": "361b0c07-35c9-41bb-d85f-313e90ea6a0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 80, 180])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, 180, 80).permute(0,2,1).unsqueeze(1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6AYsTs57-IZ",
    "outputId": "31efcce6-eaed-4e56-ecf2-78bad788b518"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 21])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYwfioTA8-rI"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6nS63AZL8_s4"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbV2Gbau9Bgc"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, scheduler, epoch=0):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss, accuracy, f1, recall, precision = 0, 0, 0, 0, 0 \n",
    "\n",
    "    total_steps = len(iterator)\n",
    "    for i, batch in enumerate(iterator):\n",
    "        specs = batch['spec'].to(device, dtype=torch.float32).unsqueeze(1)\n",
    "        labels = batch['target'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(specs)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        #calculate metrics\n",
    "        output = F.softmax(output, 1)\n",
    "        result = output.argmax(1)\n",
    "            \n",
    "        accuracy += accuracy_score(result.cpu(), labels.cpu())\n",
    "        f1 += f1_score(result.cpu(), labels.cpu(), average='micro')\n",
    "        recall += recall_score(result.cpu(), labels.cpu(), average='micro')\n",
    "        precision += precision_score(result.cpu(), labels.cpu(), average='micro')\n",
    "\n",
    "        if (i % 10 == 0):\n",
    "          step_loss = \"{:.5f}\".format(epoch_loss / (i+1))\n",
    "          step_acc = \"{:.5f}\".format(accuracy / (i+1))\n",
    "          step_f1 = \"{:.5f}\".format(f1 / (i+1))\n",
    "          step_recall = \"{:.5f}\".format(recall / (i+1))\n",
    "          step_precision = \"{:.5f}\".format(precision / (i+1))\n",
    "          print(f\"Train step {i} loss: {step_loss} acc: {step_acc} f1: {step_f1} recall {step_recall} precision: {step_precision}\")\n",
    "    #wandb.log({\"loss_train\": epoch_loss / (i+1), \"accuracy_train\": accuracy / (i+1), \"f1_train\": f1 / (i+1), \"recall_train\": recall / (i+1), \"precision_train\": precision / (i+1)})\n",
    "\n",
    "    accuracy /= (i+1)\n",
    "    f1 /= (i+1)\n",
    "    epoch_loss /= (i+1)\n",
    "    recall /= (i+1)\n",
    "    precision /= (i+1)\n",
    "\n",
    "    return epoch_loss, accuracy, f1, recall, precision\n",
    "\n",
    "def evaluate(model, iterator, criterion, epoch):\n",
    "    model.eval()\n",
    "    epoch_loss, accuracy, f1, recall, precision = 0, 0, 0, 0, 0 \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            specs = batch['spec'].to(device, dtype=torch.float32).unsqueeze(1)\n",
    "            batch_size = specs.shape[0]\n",
    "            \n",
    "            labels = batch['target'].to(device)\n",
    "            output = model(specs)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            result = output.argmax(1)\n",
    "            \n",
    "            accuracy += accuracy_score(result.cpu(), labels.cpu())\n",
    "            f1 += f1_score(result.cpu(), labels.cpu(), average='micro')\n",
    "            recall += recall_score(result.cpu(), labels.cpu(), average='micro')\n",
    "            precision += precision_score(result.cpu(), labels.cpu(), average='micro')\n",
    "        \n",
    "    #wandb.log({\"loss_train\": epoch_loss / (i+1), \"accuracy_train\": accuracy / (i+1), \"f1_train\": f1 / (i+1), \"recall_train\": recall / (i+1), \"precision_train\": precision / (i+1)})\n",
    "\n",
    "    accuracy /= (i+1)\n",
    "    f1 /= (i+1)\n",
    "    epoch_loss /= (i+1)\n",
    "    recall /= (i+1)\n",
    "    precision /= (i+1)\n",
    "    \n",
    "    return epoch_loss, accuracy, f1, recall, precision\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7YX1SiNu9GdJ"
   },
   "outputs": [],
   "source": [
    "# wandb.init(project='emble_audio_classification', entity='miana')\n",
    "# config = wandb.config\n",
    "\n",
    "# change model below\n",
    "# model = CNNNetwork().to(device)\n",
    "model = Classifier(num_classes=num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lambda2 = lambda epoch: epoch * 0.95\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer,  lr_lambda=[lambda2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hwRjVHTb9QDJ",
    "outputId": "8a0604c6-544d-4064-b31a-857fe80c6f79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step 0 loss: 3.14848 acc: 0.04167 f1: 0.04167 recall 0.04167 precision: 0.04167\n",
      "Train step 10 loss: 3.18255 acc: 0.05303 f1: 0.05303 recall 0.05303 precision: 0.05303\n",
      "Train step 20 loss: 3.18272 acc: 0.05109 f1: 0.05109 recall 0.05109 precision: 0.05109\n",
      "Train step 30 loss: 3.18904 acc: 0.04973 f1: 0.04973 recall 0.04973 precision: 0.04973\n",
      "Train step 40 loss: 3.18991 acc: 0.04802 f1: 0.04802 recall 0.04802 precision: 0.04802\n",
      "Train step 50 loss: 3.18614 acc: 0.04841 f1: 0.04841 recall 0.04841 precision: 0.04841\n",
      "Train step 60 loss: 3.18214 acc: 0.04764 f1: 0.04764 recall 0.04764 precision: 0.04764\n",
      "Train step 70 loss: 3.18971 acc: 0.04739 f1: 0.04739 recall 0.04739 precision: 0.04739\n",
      "Train step 80 loss: 3.19204 acc: 0.04771 f1: 0.04771 recall 0.04771 precision: 0.04771\n",
      "Train step 90 loss: 3.19120 acc: 0.04796 f1: 0.04796 recall 0.04796 precision: 0.04796\n",
      "Train step 100 loss: 3.19025 acc: 0.04755 f1: 0.04755 recall 0.04755 precision: 0.04755\n",
      "Train step 110 loss: 3.19192 acc: 0.04683 f1: 0.04683 recall 0.04683 precision: 0.04683\n",
      "Train step 120 loss: 3.19151 acc: 0.04588 f1: 0.04588 recall 0.04588 precision: 0.04588\n",
      "Train step 130 loss: 3.19194 acc: 0.04572 f1: 0.04572 recall 0.04572 precision: 0.04572\n",
      "Train step 140 loss: 3.19296 acc: 0.04566 f1: 0.04566 recall 0.04566 precision: 0.04566\n",
      "Train step 150 loss: 3.19191 acc: 0.04553 f1: 0.04553 recall 0.04553 precision: 0.04553\n",
      "Train step 160 loss: 3.19163 acc: 0.04510 f1: 0.04510 recall 0.04510 precision: 0.04510\n",
      "Train step 170 loss: 3.19147 acc: 0.04502 f1: 0.04502 recall 0.04502 precision: 0.04502\n",
      "Train step 180 loss: 3.19152 acc: 0.04466 f1: 0.04466 recall 0.04466 precision: 0.04466\n",
      "Train step 190 loss: 3.19024 acc: 0.04467 f1: 0.04467 recall 0.04467 precision: 0.04467\n",
      "Epoch: 01 | Time: 2 m 1 s\n",
      "\tTrain Loss: 3.19066017649952, accuracy: 0.044645941278065635, f1 0.044645941278065635, recall 0.044645941278065635, precision 0.044645941278065635\n",
      "\t Val. Loss: 3.1065167955649917, accuracy: 0.023255813953488372, f1 0.023255813953488372, recall 0.023255813953488372, precision 0.023255813953488372\n",
      "Train step 0 loss: 3.13115 acc: 0.03125 f1: 0.03125 recall 0.03125 precision: 0.03125\n",
      "Train step 10 loss: 3.14400 acc: 0.04640 f1: 0.04640 recall 0.04640 precision: 0.04640\n",
      "Train step 20 loss: 3.14318 acc: 0.05655 f1: 0.05655 recall 0.05655 precision: 0.05655\n",
      "Train step 30 loss: 3.16252 acc: 0.05276 f1: 0.05276 recall 0.05276 precision: 0.05276\n",
      "Train step 40 loss: 3.17950 acc: 0.04903 f1: 0.04903 recall 0.04903 precision: 0.04903\n",
      "Train step 50 loss: 3.18096 acc: 0.04984 f1: 0.04984 recall 0.04984 precision: 0.04984\n",
      "Train step 60 loss: 3.18205 acc: 0.04969 f1: 0.04969 recall 0.04969 precision: 0.04969\n",
      "Train step 70 loss: 3.18436 acc: 0.04724 f1: 0.04724 recall 0.04724 precision: 0.04724\n",
      "Train step 80 loss: 3.18499 acc: 0.04655 f1: 0.04655 recall 0.04655 precision: 0.04655\n",
      "Train step 90 loss: 3.18502 acc: 0.04590 f1: 0.04590 recall 0.04590 precision: 0.04590\n",
      "Train step 100 loss: 3.18514 acc: 0.04476 f1: 0.04476 recall 0.04476 precision: 0.04476\n",
      "Train step 110 loss: 3.18451 acc: 0.04401 f1: 0.04401 recall 0.04401 precision: 0.04401\n",
      "Train step 120 loss: 3.18441 acc: 0.04365 f1: 0.04365 recall 0.04365 precision: 0.04365\n",
      "Train step 130 loss: 3.18481 acc: 0.04270 f1: 0.04270 recall 0.04270 precision: 0.04270\n",
      "Train step 140 loss: 3.18718 acc: 0.04189 f1: 0.04189 recall 0.04189 precision: 0.04189\n",
      "Train step 150 loss: 3.18726 acc: 0.04187 f1: 0.04187 recall 0.04187 precision: 0.04187\n",
      "Train step 160 loss: 3.18792 acc: 0.04173 f1: 0.04173 recall 0.04173 precision: 0.04173\n",
      "Train step 170 loss: 3.18796 acc: 0.04154 f1: 0.04154 recall 0.04154 precision: 0.04154\n",
      "Train step 180 loss: 3.18867 acc: 0.04184 f1: 0.04184 recall 0.04184 precision: 0.04184\n",
      "Train step 190 loss: 3.18978 acc: 0.04123 f1: 0.04123 recall 0.04123 precision: 0.04123\n",
      "Epoch: 02 | Time: 2 m 0 s\n",
      "\tTrain Loss: 3.19017567906355, accuracy: 0.041083765112262506, f1 0.041083765112262506, recall 0.041083765112262506, precision 0.041083765112262506\n",
      "\t Val. Loss: 3.1035206012947616, accuracy: 0.02422480620155039, f1 0.02422480620155039, recall 0.02422480620155039, precision 0.02422480620155039\n",
      "Train step 0 loss: 3.18315 acc: 0.06250 f1: 0.06250 recall 0.06250 precision: 0.06250\n",
      "Train step 10 loss: 3.20087 acc: 0.04356 f1: 0.04356 recall 0.04356 precision: 0.04356\n",
      "Train step 20 loss: 3.20278 acc: 0.03919 f1: 0.03919 recall 0.03919 precision: 0.03919\n",
      "Train step 30 loss: 3.20564 acc: 0.04167 f1: 0.04167 recall 0.04167 precision: 0.04167\n",
      "Train step 40 loss: 3.20669 acc: 0.04014 f1: 0.04014 recall 0.04014 precision: 0.04014\n",
      "Train step 50 loss: 3.20409 acc: 0.04126 f1: 0.04126 recall 0.04126 precision: 0.04126\n",
      "Train step 60 loss: 3.20239 acc: 0.04303 f1: 0.04303 recall 0.04303 precision: 0.04303\n",
      "Train step 70 loss: 3.20138 acc: 0.04343 f1: 0.04343 recall 0.04343 precision: 0.04343\n",
      "Train step 80 loss: 3.19939 acc: 0.04321 f1: 0.04321 recall 0.04321 precision: 0.04321\n",
      "Train step 90 loss: 3.19841 acc: 0.04247 f1: 0.04247 recall 0.04247 precision: 0.04247\n",
      "Train step 100 loss: 3.19787 acc: 0.04198 f1: 0.04198 recall 0.04198 precision: 0.04198\n",
      "Train step 110 loss: 3.19696 acc: 0.04185 f1: 0.04185 recall 0.04185 precision: 0.04185\n",
      "Train step 120 loss: 3.19540 acc: 0.04149 f1: 0.04149 recall 0.04149 precision: 0.04149\n",
      "Train step 130 loss: 3.19686 acc: 0.04079 f1: 0.04079 recall 0.04079 precision: 0.04079\n",
      "Train step 140 loss: 3.19736 acc: 0.04159 f1: 0.04159 recall 0.04159 precision: 0.04159\n",
      "Train step 150 loss: 3.19798 acc: 0.04098 f1: 0.04098 recall 0.04098 precision: 0.04098\n",
      "Train step 160 loss: 3.19629 acc: 0.04102 f1: 0.04102 recall 0.04102 precision: 0.04102\n",
      "Train step 170 loss: 3.19588 acc: 0.04100 f1: 0.04100 recall 0.04100 precision: 0.04100\n",
      "Train step 180 loss: 3.19557 acc: 0.04103 f1: 0.04103 recall 0.04103 precision: 0.04103\n",
      "Train step 190 loss: 3.19556 acc: 0.04118 f1: 0.04118 recall 0.04118 precision: 0.04118\n",
      "Epoch: 03 | Time: 2 m 0 s\n",
      "\tTrain Loss: 3.195846621854318, accuracy: 0.04097582037996549, f1 0.04097582037996549, recall 0.04097582037996549, precision 0.04097582037996549\n",
      "\t Val. Loss: 3.105469925459041, accuracy: 0.023255813953488372, f1 0.023255813953488372, recall 0.023255813953488372, precision 0.023255813953488372\n",
      "Train step 0 loss: 3.26994 acc: 0.02083 f1: 0.02083 recall 0.02083 precision: 0.02083\n",
      "Train step 10 loss: 3.16423 acc: 0.04924 f1: 0.04924 recall 0.04924 precision: 0.04924\n",
      "Train step 20 loss: 3.18402 acc: 0.04216 f1: 0.04216 recall 0.04216 precision: 0.04216\n",
      "Train step 30 loss: 3.19258 acc: 0.04335 f1: 0.04335 recall 0.04335 precision: 0.04335\n",
      "Train step 40 loss: 3.18709 acc: 0.04522 f1: 0.04522 recall 0.04522 precision: 0.04522\n",
      "Train step 50 loss: 3.18596 acc: 0.04432 f1: 0.04432 recall 0.04432 precision: 0.04432\n",
      "Train step 60 loss: 3.18468 acc: 0.04457 f1: 0.04457 recall 0.04457 precision: 0.04457\n",
      "Train step 70 loss: 3.18536 acc: 0.04563 f1: 0.04563 recall 0.04563 precision: 0.04563\n",
      "Train step 80 loss: 3.18763 acc: 0.04437 f1: 0.04437 recall 0.04437 precision: 0.04437\n",
      "Train step 90 loss: 3.19040 acc: 0.04304 f1: 0.04304 recall 0.04304 precision: 0.04304\n",
      "Train step 100 loss: 3.18943 acc: 0.04321 f1: 0.04321 recall 0.04321 precision: 0.04321\n",
      "Train step 110 loss: 3.18635 acc: 0.04439 f1: 0.04439 recall 0.04439 precision: 0.04439\n",
      "Train step 120 loss: 3.18763 acc: 0.04511 f1: 0.04511 recall 0.04511 precision: 0.04511\n",
      "Train step 130 loss: 3.18853 acc: 0.04572 f1: 0.04572 recall 0.04572 precision: 0.04572\n",
      "Train step 140 loss: 3.18979 acc: 0.04610 f1: 0.04610 recall 0.04610 precision: 0.04610\n",
      "Train step 150 loss: 3.18928 acc: 0.04601 f1: 0.04601 recall 0.04601 precision: 0.04601\n",
      "Train step 160 loss: 3.19043 acc: 0.04535 f1: 0.04535 recall 0.04535 precision: 0.04535\n",
      "Train step 170 loss: 3.19177 acc: 0.04441 f1: 0.04441 recall 0.04441 precision: 0.04441\n",
      "Train step 180 loss: 3.19201 acc: 0.04408 f1: 0.04408 recall 0.04408 precision: 0.04408\n",
      "Train step 190 loss: 3.19332 acc: 0.04434 f1: 0.04434 recall 0.04434 precision: 0.04434\n",
      "Epoch: 04 | Time: 2 m 1 s\n",
      "\tTrain Loss: 3.1930424450592674, accuracy: 0.04437967760506621, f1 0.04437967760506621, recall 0.04437967760506621, precision 0.04437967760506621\n",
      "\t Val. Loss: 3.108057436092879, accuracy: 0.02180232558139535, f1 0.02180232558139535, recall 0.02180232558139535, precision 0.02180232558139535\n",
      "Train step 0 loss: 3.11673 acc: 0.04167 f1: 0.04167 recall 0.04167 precision: 0.04167\n",
      "Train step 10 loss: 3.17000 acc: 0.03409 f1: 0.03409 recall 0.03409 precision: 0.03409\n",
      "Train step 20 loss: 3.18676 acc: 0.03770 f1: 0.03770 recall 0.03770 precision: 0.03770\n",
      "Train step 30 loss: 3.19488 acc: 0.03864 f1: 0.03864 recall 0.03864 precision: 0.03864\n",
      "Train step 40 loss: 3.19046 acc: 0.03913 f1: 0.03913 recall 0.03913 precision: 0.03913\n",
      "Train step 50 loss: 3.19612 acc: 0.03860 f1: 0.03860 recall 0.03860 precision: 0.03860\n",
      "Train step 60 loss: 3.19457 acc: 0.04030 f1: 0.04030 recall 0.04030 precision: 0.04030\n",
      "Train step 70 loss: 3.19352 acc: 0.04049 f1: 0.04049 recall 0.04049 precision: 0.04049\n",
      "Train step 80 loss: 3.19373 acc: 0.03948 f1: 0.03948 recall 0.03948 precision: 0.03948\n",
      "Train step 90 loss: 3.19169 acc: 0.03961 f1: 0.03961 recall 0.03961 precision: 0.03961\n",
      "Train step 100 loss: 3.19078 acc: 0.03971 f1: 0.03971 recall 0.03971 precision: 0.03971\n",
      "Train step 110 loss: 3.19082 acc: 0.04073 f1: 0.04073 recall 0.04073 precision: 0.04073\n",
      "Train step 120 loss: 3.19132 acc: 0.04106 f1: 0.04106 recall 0.04106 precision: 0.04106\n",
      "Train step 130 loss: 3.19077 acc: 0.04095 f1: 0.04095 recall 0.04095 precision: 0.04095\n",
      "Train step 140 loss: 3.18986 acc: 0.04048 f1: 0.04048 recall 0.04048 precision: 0.04048\n",
      "Train step 150 loss: 3.18840 acc: 0.04070 f1: 0.04070 recall 0.04070 precision: 0.04070\n",
      "Train step 160 loss: 3.19097 acc: 0.04057 f1: 0.04057 recall 0.04057 precision: 0.04057\n",
      "Train step 170 loss: 3.19045 acc: 0.04106 f1: 0.04106 recall 0.04106 precision: 0.04106\n",
      "Train step 180 loss: 3.18997 acc: 0.04132 f1: 0.04132 recall 0.04132 precision: 0.04132\n",
      "Train step 190 loss: 3.19168 acc: 0.04161 f1: 0.04161 recall 0.04161 precision: 0.04161\n",
      "Epoch: 05 | Time: 1 m 59 s\n",
      "\tTrain Loss: 3.1912488047940744, accuracy: 0.04168465745538283, f1 0.04168465745538283, recall 0.04168465745538283, precision 0.04168465745538283\n",
      "\t Val. Loss: 3.113833270331686, accuracy: 0.02422480620155039, f1 0.02422480620155039, recall 0.02422480620155039, precision 0.02422480620155039\n",
      "Train step 0 loss: 3.23409 acc: 0.01042 f1: 0.01042 recall 0.01042 precision: 0.01042\n",
      "Train step 10 loss: 3.20094 acc: 0.04261 f1: 0.04261 recall 0.04261 precision: 0.04261\n",
      "Train step 20 loss: 3.19343 acc: 0.04018 f1: 0.04018 recall 0.04018 precision: 0.04018\n",
      "Train step 30 loss: 3.19274 acc: 0.04099 f1: 0.04099 recall 0.04099 precision: 0.04099\n",
      "Train step 40 loss: 3.19490 acc: 0.03862 f1: 0.03862 recall 0.03862 precision: 0.03862\n",
      "Train step 50 loss: 3.19744 acc: 0.03656 f1: 0.03656 recall 0.03656 precision: 0.03656\n",
      "Train step 60 loss: 3.19794 acc: 0.03603 f1: 0.03603 recall 0.03603 precision: 0.03603\n",
      "Train step 70 loss: 3.19853 acc: 0.03756 f1: 0.03756 recall 0.03756 precision: 0.03756\n",
      "Train step 80 loss: 3.19777 acc: 0.03704 f1: 0.03704 recall 0.03704 precision: 0.03704\n",
      "Train step 90 loss: 3.19805 acc: 0.03823 f1: 0.03823 recall 0.03823 precision: 0.03823\n",
      "Train step 100 loss: 3.19954 acc: 0.03775 f1: 0.03775 recall 0.03775 precision: 0.03775\n",
      "Train step 110 loss: 3.19605 acc: 0.03857 f1: 0.03857 recall 0.03857 precision: 0.03857\n",
      "Train step 120 loss: 3.19571 acc: 0.03857 f1: 0.03857 recall 0.03857 precision: 0.03857\n",
      "Train step 130 loss: 3.19696 acc: 0.03920 f1: 0.03920 recall 0.03920 precision: 0.03920\n",
      "Train step 140 loss: 3.19821 acc: 0.03886 f1: 0.03886 recall 0.03886 precision: 0.03886\n",
      "Train step 150 loss: 3.19794 acc: 0.03905 f1: 0.03905 recall 0.03905 precision: 0.03905\n",
      "Train step 160 loss: 3.19677 acc: 0.03992 f1: 0.03992 recall 0.03992 precision: 0.03992\n",
      "Train step 170 loss: 3.19595 acc: 0.04045 f1: 0.04045 recall 0.04045 precision: 0.04045\n",
      "Train step 180 loss: 3.19501 acc: 0.04057 f1: 0.04057 recall 0.04057 precision: 0.04057\n",
      "Train step 190 loss: 3.19615 acc: 0.04019 f1: 0.04019 recall 0.04019 precision: 0.04019\n",
      "Epoch: 06 | Time: 2 m 0 s\n",
      "\tTrain Loss: 3.196142924264305, accuracy: 0.040500863557858376, f1 0.040500863557858376, recall 0.040500863557858376, precision 0.040500863557858376\n",
      "\t Val. Loss: 3.107020990793095, accuracy: 0.025193798449612403, f1 0.025193798449612403, recall 0.025193798449612403, precision 0.025193798449612403\n",
      "Train step 0 loss: 3.19198 acc: 0.03125 f1: 0.03125 recall 0.03125 precision: 0.03125\n",
      "Train step 10 loss: 3.20189 acc: 0.03220 f1: 0.03220 recall 0.03220 precision: 0.03220\n",
      "Train step 20 loss: 3.20304 acc: 0.03571 f1: 0.03571 recall 0.03571 precision: 0.03571\n",
      "Train step 30 loss: 3.19817 acc: 0.04032 f1: 0.04032 recall 0.04032 precision: 0.04032\n",
      "Train step 40 loss: 3.19779 acc: 0.04090 f1: 0.04090 recall 0.04090 precision: 0.04090\n",
      "Train step 50 loss: 3.19884 acc: 0.03983 f1: 0.03983 recall 0.03983 precision: 0.03983\n",
      "Train step 60 loss: 3.19843 acc: 0.04030 f1: 0.04030 recall 0.04030 precision: 0.04030\n",
      "Train step 70 loss: 3.19339 acc: 0.04079 f1: 0.04079 recall 0.04079 precision: 0.04079\n",
      "Train step 80 loss: 3.19645 acc: 0.04090 f1: 0.04090 recall 0.04090 precision: 0.04090\n",
      "Train step 90 loss: 3.19634 acc: 0.04041 f1: 0.04041 recall 0.04041 precision: 0.04041\n",
      "Train step 100 loss: 3.19572 acc: 0.04177 f1: 0.04177 recall 0.04177 precision: 0.04177\n",
      "Train step 110 loss: 3.19554 acc: 0.04195 f1: 0.04195 recall 0.04195 precision: 0.04195\n",
      "Train step 120 loss: 3.19401 acc: 0.04210 f1: 0.04210 recall 0.04210 precision: 0.04210\n",
      "Train step 130 loss: 3.19473 acc: 0.04159 f1: 0.04159 recall 0.04159 precision: 0.04159\n",
      "Train step 140 loss: 3.19580 acc: 0.04093 f1: 0.04093 recall 0.04093 precision: 0.04093\n",
      "Train step 150 loss: 3.19664 acc: 0.04139 f1: 0.04139 recall 0.04139 precision: 0.04139\n",
      "Train step 160 loss: 3.19652 acc: 0.04147 f1: 0.04147 recall 0.04147 precision: 0.04147\n",
      "Train step 170 loss: 3.19474 acc: 0.04130 f1: 0.04130 recall 0.04130 precision: 0.04130\n",
      "Train step 180 loss: 3.19523 acc: 0.04121 f1: 0.04121 recall 0.04121 precision: 0.04121\n",
      "Train step 190 loss: 3.19482 acc: 0.04068 f1: 0.04068 recall 0.04068 precision: 0.04068\n",
      "Epoch: 07 | Time: 2 m 0 s\n",
      "\tTrain Loss: 3.194693125591377, accuracy: 0.040695164075993086, f1 0.040695164075993086, recall 0.040695164075993086, precision 0.040695164075993086\n",
      "\t Val. Loss: 3.1108166053313617, accuracy: 0.022771317829457363, f1 0.022771317829457363, recall 0.022771317829457363, precision 0.022771317829457363\n",
      "Train step 0 loss: 3.23325 acc: 0.02083 f1: 0.02083 recall 0.02083 precision: 0.02083\n",
      "Train step 10 loss: 3.21049 acc: 0.03314 f1: 0.03314 recall 0.03314 precision: 0.03314\n",
      "Train step 20 loss: 3.19625 acc: 0.03770 f1: 0.03770 recall 0.03770 precision: 0.03770\n",
      "Train step 30 loss: 3.19125 acc: 0.03495 f1: 0.03495 recall 0.03495 precision: 0.03495\n",
      "Train step 40 loss: 3.18988 acc: 0.03760 f1: 0.03760 recall 0.03760 precision: 0.03760\n",
      "Train step 50 loss: 3.19220 acc: 0.03676 f1: 0.03676 recall 0.03676 precision: 0.03676\n",
      "Train step 60 loss: 3.19086 acc: 0.03808 f1: 0.03808 recall 0.03808 precision: 0.03808\n",
      "Train step 70 loss: 3.19307 acc: 0.03785 f1: 0.03785 recall 0.03785 precision: 0.03785\n",
      "Train step 80 loss: 3.19253 acc: 0.03819 f1: 0.03819 recall 0.03819 precision: 0.03819\n",
      "Train step 90 loss: 3.19570 acc: 0.03846 f1: 0.03846 recall 0.03846 precision: 0.03846\n",
      "Train step 100 loss: 3.19406 acc: 0.04012 f1: 0.04012 recall 0.04012 precision: 0.04012\n",
      "Train step 110 loss: 3.19440 acc: 0.03885 f1: 0.03885 recall 0.03885 precision: 0.03885\n",
      "Train step 120 loss: 3.19446 acc: 0.03943 f1: 0.03943 recall 0.03943 precision: 0.03943\n",
      "Train step 130 loss: 3.19537 acc: 0.03833 f1: 0.03833 recall 0.03833 precision: 0.03833\n",
      "Train step 140 loss: 3.19597 acc: 0.03864 f1: 0.03864 recall 0.03864 precision: 0.03864\n",
      "Train step 150 loss: 3.19651 acc: 0.03877 f1: 0.03877 recall 0.03877 precision: 0.03877\n",
      "Train step 160 loss: 3.19624 acc: 0.03876 f1: 0.03876 recall 0.03876 precision: 0.03876\n",
      "Train step 170 loss: 3.19628 acc: 0.03935 f1: 0.03935 recall 0.03935 precision: 0.03935\n",
      "Train step 180 loss: 3.19497 acc: 0.03971 f1: 0.03971 recall 0.03971 precision: 0.03971\n",
      "Train step 190 loss: 3.19298 acc: 0.04019 f1: 0.04019 recall 0.04019 precision: 0.04019\n",
      "Epoch: 08 | Time: 1 m 59 s\n",
      "\tTrain Loss: 3.1932248167423385, accuracy: 0.04028497409326424, f1 0.04028497409326424, recall 0.04028497409326424, precision 0.04028497409326424\n",
      "\t Val. Loss: 3.114004835601925, accuracy: 0.022771317829457363, f1 0.022771317829457363, recall 0.022771317829457363, precision 0.022771317829457363\n",
      "Train step 0 loss: 3.16767 acc: 0.06250 f1: 0.06250 recall 0.06250 precision: 0.06250\n",
      "Train step 10 loss: 3.16723 acc: 0.03693 f1: 0.03693 recall 0.03693 precision: 0.03693\n",
      "Train step 20 loss: 3.17992 acc: 0.03423 f1: 0.03423 recall 0.03423 precision: 0.03423\n",
      "Train step 30 loss: 3.19294 acc: 0.03595 f1: 0.03595 recall 0.03595 precision: 0.03595\n",
      "Train step 40 loss: 3.19332 acc: 0.03887 f1: 0.03887 recall 0.03887 precision: 0.03887\n",
      "Train step 50 loss: 3.19374 acc: 0.03922 f1: 0.03922 recall 0.03922 precision: 0.03922\n",
      "Train step 60 loss: 3.19393 acc: 0.03996 f1: 0.03996 recall 0.03996 precision: 0.03996\n",
      "Train step 70 loss: 3.19386 acc: 0.04064 f1: 0.04064 recall 0.04064 precision: 0.04064\n",
      "Train step 80 loss: 3.19388 acc: 0.03999 f1: 0.03999 recall 0.03999 precision: 0.03999\n",
      "Train step 90 loss: 3.19471 acc: 0.03995 f1: 0.03995 recall 0.03995 precision: 0.03995\n",
      "Train step 100 loss: 3.19660 acc: 0.03981 f1: 0.03981 recall 0.03981 precision: 0.03981\n",
      "Train step 110 loss: 3.19620 acc: 0.03998 f1: 0.03998 recall 0.03998 precision: 0.03998\n",
      "Train step 120 loss: 3.19767 acc: 0.04063 f1: 0.04063 recall 0.04063 precision: 0.04063\n",
      "Train step 130 loss: 3.19768 acc: 0.03984 f1: 0.03984 recall 0.03984 precision: 0.03984\n",
      "Train step 140 loss: 3.19833 acc: 0.03960 f1: 0.03960 recall 0.03960 precision: 0.03960\n",
      "Train step 150 loss: 3.19775 acc: 0.03987 f1: 0.03987 recall 0.03987 precision: 0.03987\n",
      "Train step 160 loss: 3.19766 acc: 0.03940 f1: 0.03940 recall 0.03940 precision: 0.03940\n",
      "Train step 170 loss: 3.19995 acc: 0.03911 f1: 0.03911 recall 0.03911 precision: 0.03911\n",
      "Train step 180 loss: 3.19902 acc: 0.03862 f1: 0.03862 recall 0.03862 precision: 0.03862\n",
      "Train step 190 loss: 3.19960 acc: 0.03856 f1: 0.03856 recall 0.03856 precision: 0.03856\n",
      "Epoch: 09 | Time: 1 m 59 s\n",
      "\tTrain Loss: 3.198770180885038, accuracy: 0.038762953367875656, f1 0.038762953367875656, recall 0.038762953367875656, precision 0.038762953367875656\n",
      "\t Val. Loss: 3.108166449753813, accuracy: 0.02374031007751938, f1 0.02374031007751938, recall 0.02374031007751938, precision 0.02374031007751938\n",
      "Train step 0 loss: 3.15795 acc: 0.02083 f1: 0.02083 recall 0.02083 precision: 0.02083\n",
      "Train step 10 loss: 3.16320 acc: 0.04545 f1: 0.04545 recall 0.04545 precision: 0.04545\n",
      "Train step 20 loss: 3.18361 acc: 0.04067 f1: 0.04067 recall 0.04067 precision: 0.04067\n",
      "Train step 30 loss: 3.18853 acc: 0.04032 f1: 0.04032 recall 0.04032 precision: 0.04032\n",
      "Train step 40 loss: 3.18503 acc: 0.04116 f1: 0.04116 recall 0.04116 precision: 0.04116\n",
      "Train step 50 loss: 3.18831 acc: 0.04085 f1: 0.04085 recall 0.04085 precision: 0.04085\n",
      "Train step 60 loss: 3.18979 acc: 0.04133 f1: 0.04133 recall 0.04133 precision: 0.04133\n",
      "Train step 70 loss: 3.18779 acc: 0.04123 f1: 0.04123 recall 0.04123 precision: 0.04123\n",
      "Train step 80 loss: 3.18803 acc: 0.04270 f1: 0.04270 recall 0.04270 precision: 0.04270\n",
      "Train step 90 loss: 3.18793 acc: 0.04224 f1: 0.04224 recall 0.04224 precision: 0.04224\n",
      "Train step 100 loss: 3.19200 acc: 0.04136 f1: 0.04136 recall 0.04136 precision: 0.04136\n",
      "Train step 110 loss: 3.18933 acc: 0.04195 f1: 0.04195 recall 0.04195 precision: 0.04195\n",
      "Train step 120 loss: 3.18860 acc: 0.04244 f1: 0.04244 recall 0.04244 precision: 0.04244\n",
      "Train step 130 loss: 3.18883 acc: 0.04286 f1: 0.04286 recall 0.04286 precision: 0.04286\n",
      "Train step 140 loss: 3.18869 acc: 0.04314 f1: 0.04314 recall 0.04314 precision: 0.04314\n",
      "Train step 150 loss: 3.19055 acc: 0.04291 f1: 0.04291 recall 0.04291 precision: 0.04291\n",
      "Train step 160 loss: 3.19062 acc: 0.04270 f1: 0.04270 recall 0.04270 precision: 0.04270\n",
      "Train step 170 loss: 3.19207 acc: 0.04191 f1: 0.04191 recall 0.04191 precision: 0.04191\n",
      "Train step 180 loss: 3.19088 acc: 0.04172 f1: 0.04172 recall 0.04172 precision: 0.04172\n",
      "Train step 190 loss: 3.18972 acc: 0.04221 f1: 0.04221 recall 0.04221 precision: 0.04221\n",
      "Epoch: 10 | Time: 1 m 59 s\n",
      "\tTrain Loss: 3.189921136964788, accuracy: 0.04232872769142198, f1 0.04232872769142198, recall 0.04232872769142198, precision 0.04232872769142198\n",
      "\t Val. Loss: 3.108010071192601, accuracy: 0.02374031007751938, f1 0.02374031007751938, recall 0.02374031007751938, precision 0.02374031007751938\n"
     ]
    }
   ],
   "source": [
    "  N_EPOCHS = 10\n",
    "\n",
    "  train_losses, val_losses = [], []\n",
    "  train_accuracies, val_accuracies = [], []\n",
    "  train_f1s, val_f1s = [], []\n",
    "\n",
    "  best_valid_loss = float('inf')\n",
    "\n",
    "  #wandb.watch(model)\n",
    "  for epoch in range(N_EPOCHS):\n",
    "      start_time = time.time()\n",
    "      train_loss, train_accuracy, train_f1, train_recall, train_precision = train(model, loader_train, optimizer, criterion, scheduler, epoch)\n",
    "      val_loss, val_accuracy, val_f1, val_recall, val_precision = evaluate(model, loader_test, criterion, epoch)\n",
    "      \n",
    "      end_time = time.time()\n",
    "      \n",
    "      # fill data\n",
    "      train_losses.append(train_loss)\n",
    "      val_losses.append(val_loss)\n",
    "      train_accuracies.append(train_accuracy)\n",
    "      train_f1s.append(train_f1)\n",
    "      val_accuracies.append(val_accuracy)\n",
    "      val_f1s.append(val_f1)\n",
    "      \n",
    "      epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "      torch.save(model.state_dict(), 'best-val-model.pt')\n",
    "\n",
    "      print(f'Epoch: {epoch+1:02} | Time: {epoch_mins} m {epoch_secs} s')\n",
    "      print(f'\\tTrain Loss: {train_loss}, accuracy: {train_accuracy}, f1 {train_f1}, recall {train_recall}, precision {train_precision}')\n",
    "      print(f'\\t Val. Loss: {val_loss}, accuracy: {val_accuracy}, f1 {val_f1}, recall {val_recall}, precision {val_precision}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MOS_Models_Development_CNN2D.ipynb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
